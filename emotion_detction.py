# -*- coding: utf-8 -*-
"""Emotion detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CCCpj99UfXwdurskH3qHbEuWAz1n7P17
"""

# Commented out IPython magic to ensure Python compatibility.
import os 
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.transforms as tt
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

train_tfms = tt.Compose([tt.Grayscale(num_output_channels=3),
                        # tt.Resize([28,28]),
                         #tt.RandomHorizontalFlip(),
                         #tt.RandomRotation(30),
                         tt.ToTensor()])

valid_tfms = tt.Compose([tt.Grayscale(num_output_channels=3),
                         #tt.Resize([28,28]),
                         tt.ToTensor()])

!unzip /content/sample_data/archive2.zip

dir = "/content"

trainds = ImageFolder(dir + "/train",train_tfms)
testds = ImageFolder(dir +"/test",valid_tfms)

torch.Size(trainds)

classes=('angry','disgusted','fearful','happy','neutral','sad','suprised')

import numpy as np

def imshow(img):
  img=img / 2 + 0.5   #unnormalize
  npimg=img.numpy()
  plt.imshow(np.transpose(npimg,(1,2,0)))
  plt.show()





testloader=torch.utils.data.DataLoader(testds,batch_size=4,shuffle=False)

trainloader=torch.utils.data.DataLoader(trainds,batch_size=4,shuffle=True)

images,labels=next(iter(trainloader))
imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(2)))
print(images.shape)

from torchvision.utils import make_grid

for images, _ in trainloader:
    print('images.shape:', images.shape)
    plt.figure(figsize=(16, 8))
    plt.axis("off")
    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0))) # move the channel dimension
    break

_ = plt.suptitle("Images", y=0.92, fontsize=16)

def conv_block(in_channels, out_channels, pool=False):
    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), 
              nn.BatchNorm2d(out_channels), 
              nn.ELU(inplace=True)]
    if pool: layers.append(nn.MaxPool2d(2))
    return nn.Sequential(*layers)

class ResNet(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        
        self.conv1 = conv_block(in_channels, 128)
        self.conv2 = conv_block(128, 128, pool=True)
        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))
        self.drop1 = nn.Dropout(0.5)
        
        self.conv3 = conv_block(128, 256)
        self.conv4 = conv_block(256, 256, pool=True)
        self.res2 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))
        self.drop2 = nn.Dropout(0.5)
        
        self.conv5 = conv_block(256, 512)
        self.conv6 = conv_block(512, 512, pool=True)
        self.res3 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))
        self.drop3 = nn.Dropout(0.5)
        
        self.classifier = nn.Sequential(nn.MaxPool2d(6), 
                                        nn.Flatten(),
                                        nn.Linear(512, num_classes))
        
    def forward(self, xb):
        out = self.conv1(xb)
        out = self.conv2(out)
        out = self.res1(out) + out
        out = self.drop1(out)
        
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.res2(out) + out
        out = self.drop2(out)
        
        out = self.conv5(out)
        out = self.conv6(out)
        out = self.res3(out) + out
        out = self.drop3(out)
        
        out = self.classifier(out)
        return out

def to_device(data, device):
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

import torchvision.models as models

resnet50 = models.resnet50(pretrained = True)

resnet50

model = to_device(ResNet(1, len(classes_train)), device)
model

import torch.optim as optim
criterion=nn.CrossEntropyLoss()
optimizer = optim.SGD(resnet50.parameters(),lr=0.001,momentum=0.9)

for epoch in range(3):
  running_loss=0.0
  for i,data in enumerate(trainloader,0):
    inputs,labels=data
    optimizer.zero_grad()
    outputs=resnet50(inputs)
    loss=criterion(outputs,labels)
    loss.backward()
    optimizer.step()


    running_loss += loss.item()
    if i%2000 == 1999:
      print('[%d,%5d] loss:%.3f'%
            (epoch + 1 , i+1,running_loss/2000))
      running_loss=0.0

  print('finished training')

